{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine filtering by flavours\n",
    "In this notebook I will extract the flavours from the wine descriptions I have from the Wine Enthusiast website and I will also use an additional data sources with flavours and spices to mix and match. I will also implement a word2vec model. The list with the word2vec model will be used to create a filtering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "# import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# nlp = spacy.load('en')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/home/fykos/Documents/workspace/wine_beer_exploration/')\n",
    "os.chdir('C://Users/vasileios.vyzas/Documents/workspace/Projects/Miscellaneous/wine_recommendation_system//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('data/raw/winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(review):\n",
    "    review_letters = re.sub('[^a-zA-Z]', ' ', str(review))\n",
    "    review_letters = review_letters.lower()\n",
    "    return (\" \".join(review_letters.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ls = [word for word in review.split() if word not in stop_words]\n",
    "    txt = \" \".join(ls)\n",
    "    return (txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the flavours from the descriptions\n",
    "Here I will use spacy to extract all the nouns and noun phrases which is the type of the fruit flavours and I will filter this list better with another list I have from external sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun_finder(review):\n",
    "    blob = nlp(normalize(review))\n",
    "    return (\" \".join([token.text for token in blob if token.tag_ == 'NN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list = wine['description'].map(noun_finder).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fruit broom brimstone herb palate offering apple citrus sage acidity',\n",
       "       'fruity wine firm berry acidity',\n",
       "       'lime flesh rind pineapple acidity wine steel', ...,\n",
       "       'gravel soil wine character fruity spice favor structure wine age couple',\n",
       "       'style pinot gris acidity weight core spice apple structure wine age drink',\n",
       "       'spiciness texture fruit profile feel aftertaste drink'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = ['wine', 'pasta', 'whole', 'character', 'cabernet', 'wood', 'spicy', 'tannins', 'crisp', 'juicy', 'fruits', 'blend', 'sauvignon', 'structure', 'fruity', 'aromas', 'flavors', 'ripe', 'syrup', 'cake', 'cheese', 'cream', 'bean', 'hard', 'milk', 'sauce', 'barbecue', 'steak', 'rock', 'powder', 'ruby', 'oil', 'salt', 'pastry', 'flesh', 'bitter', 'sugar', 'leather', 'herbal', 'creamy', 'table', 'brown', 'golden', 'gold', 'extract', 'broad', 'natural', 'salmon', 'tongue', 'dry', 'pure', 'root', 'sea', 'port', 'chewy', 'solid', 'blue', 'pink', 'ground', 'beef', 'purple', 'spring', 'lean', 'raw', 'red', 'black', 'white', 'yellow', 'mature', 'tropical', 'meat', 'wild', 'new', 'juice', 'firm', 'sweet', 'fresh', 'light', 'flower', 'green', 'soft', 'skin', 'spice', 'dark', 'herb', 'palate', 'valley', 'finish', 'drink', 'flavor', 'fruit', 'aroma', 'note', 'texture', 'thi', 'acidity']\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stops)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features holds a list of all the words in the tfidf's vocabulary in the same order as the column in the matrix\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "weights = np.asarray(tfidf_matrix.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term':features, 'weights':weights})\n",
    "weights_df = weights_df.sort_values(by='weights', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the foods database \n",
    "food_db = pd.read_csv('data/modified//8b. AUSNUT 2011-13 AHS Food Nutrient Database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process foods\n",
    "test = set(word.strip().lower() for ls in list(map(lambda x:x.split(',') ,food_db['Food Name'].tolist())) for word in ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickout the foods from the wine list\n",
    "terms = weights_df[weights_df['weights'] > 0.001]\n",
    "foods = []\n",
    "for term in terms['term']:\n",
    "    if term in test:\n",
    "        foods.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cherry', 'berry', 'plum', 'apple', 'blackberry', 'vanilla', 'pepper', 'citrus', 'lemon', 'raspberry', 'peach', 'pear', 'chocolate', 'currant', 'licorice', 'lime', 'coffee', 'melon', 'grapefruit', 'honey', 'apricot', 'pineapple', 'strawberry', 'cinnamon', 'almond', 'mocha', 'mint', 'orange', 'jam', 'grape', 'blueberry', 'tea', 'sage', 'pie', 'caramel', 'cranberry', 'raisin', 'olive', 'tomato', 'coconut', 'butter', 'bacon', 'fig', 'mango', 'banana', 'thyme', 'prune', 'mushroom', 'pomegranate', 'butterscotch', 'ginger', 'lychee', 'mousse', 'bread', 'nut', 'truffle', 'yeast', 'jasmine', 'nectarine', 'hazelnut', 'fennel', 'liqueur', 'tart', 'herbs', 'quince', 'dill', 'watermelon', 'heart', 'lamb', 'pork', 'chicken', 'guava', 'seafood', 'maple', 'custard', 'energy', 'soy', 'beer', 'cooking', 'coating']\n"
     ]
    }
   ],
   "source": [
    "print(foods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\vasileios.vyzas/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\vasileios.vyzas/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-220f2230c7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prepare the input for the word2vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-220f2230c7b9>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prepare the input for the word2vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-0f30bbb8dee1>\u001b[0m in \u001b[0;36mremove_stopwords\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\vasileios.vyzas/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\vasileios.vyzas\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# prepare the input for the word2vec model\n",
    "ls = list(map(lambda x: word_tokenize(remove_stopwords(normalize(x))), wine['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasileios.vyzas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "## Word2Vec needs a large corpus to train in order to perform well\n",
    "cbow_model = Word2Vec(ls, min_count = 2, size = 150, window = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scents', 0.7888871431350708),\n",
       " ('notes', 0.5859709978103638),\n",
       " ('bouquet', 0.5810145735740662),\n",
       " ('whiff', 0.5469571948051453),\n",
       " ('fragrances', 0.5263883471488953),\n",
       " ('whiffs', 0.5257620215415955),\n",
       " ('rubber', 0.4845849275588989),\n",
       " ('fragrance', 0.4818279445171356),\n",
       " ('clicky', 0.47520989179611206),\n",
       " ('tones', 0.46636292338371277),\n",
       " ('blast', 0.46254128217697144),\n",
       " ('accents', 0.4550802707672119),\n",
       " ('smelling', 0.45021432638168335),\n",
       " ('aroma', 0.4491744041442871),\n",
       " ('nose', 0.4393962323665619),\n",
       " ('scent', 0.4302075505256653),\n",
       " ('soap', 0.4269176423549652),\n",
       " ('tire', 0.42656657099723816),\n",
       " ('smells', 0.41807618737220764),\n",
       " ('fur', 0.4124946892261505),\n",
       " ('resin', 0.40236401557922363),\n",
       " ('dust', 0.40189939737319946),\n",
       " ('bath', 0.3994298577308655),\n",
       " ('hay', 0.3991416096687317),\n",
       " ('pressed', 0.39890554547309875),\n",
       " ('barlett', 0.39778491854667664),\n",
       " ('candle', 0.3935548663139343),\n",
       " ('stewed', 0.3927515149116516),\n",
       " ('muddled', 0.3906274139881134),\n",
       " ('chewing', 0.38984057307243347),\n",
       " ('hide', 0.38874247670173645),\n",
       " ('underbrush', 0.3867805600166321),\n",
       " ('nuances', 0.3855820596218109),\n",
       " ('plump', 0.3851875066757202),\n",
       " ('magnolia', 0.38212162256240845),\n",
       " ('sensations', 0.3809288442134857),\n",
       " ('touches', 0.3796817660331726),\n",
       " ('overtones', 0.37891995906829834),\n",
       " ('flavors', 0.3758317828178406),\n",
       " ('hints', 0.37531986832618713),\n",
       " ('recall', 0.37249860167503357),\n",
       " ('scorched', 0.3722275197505951),\n",
       " ('suggestions', 0.3705623745918274),\n",
       " ('seckel', 0.3695160746574402),\n",
       " ('dried', 0.369300901889801),\n",
       " ('tulip', 0.36861199140548706),\n",
       " ('shadings', 0.36808058619499207),\n",
       " ('ultrasaturated', 0.36792445182800293),\n",
       " ('moist', 0.3652530908584595),\n",
       " ('latex', 0.3645360767841339),\n",
       " ('band', 0.36294251680374146),\n",
       " ('vinegar', 0.3599793612957001),\n",
       " ('raw', 0.3558139204978943),\n",
       " ('fragances', 0.35336148738861084),\n",
       " ('alluring', 0.3529921770095825),\n",
       " ('tree', 0.35242679715156555),\n",
       " ('hint', 0.3505338132381439),\n",
       " ('seed', 0.34886887669563293),\n",
       " ('steeped', 0.3481529653072357),\n",
       " ('saturated', 0.3464690148830414),\n",
       " ('skinned', 0.34388476610183716),\n",
       " ('fleshy', 0.34348729252815247),\n",
       " ('crushed', 0.34338030219078064),\n",
       " ('aromatics', 0.3420448899269104),\n",
       " ('redolent', 0.3399815559387207),\n",
       " ('roasted', 0.33784452080726624),\n",
       " ('palate', 0.33784380555152893),\n",
       " ('aid', 0.3376978039741516),\n",
       " ('flush', 0.337019145488739),\n",
       " ('powder', 0.3347899913787842),\n",
       " ('counterpoints', 0.33346855640411377),\n",
       " ('cumin', 0.3334677219390869),\n",
       " ('tensions', 0.3318994343280792),\n",
       " ('eventually', 0.3309627175331116),\n",
       " ('molasses', 0.3304334878921509),\n",
       " ('leaning', 0.33039066195487976),\n",
       " ('freshener', 0.32980403304100037),\n",
       " ('sawdust', 0.32946154475212097),\n",
       " ('chopped', 0.3283097445964813),\n",
       " ('wet', 0.3272499144077301),\n",
       " ('spanish', 0.326629102230072),\n",
       " ('aromatically', 0.3266217112541199),\n",
       " ('freshly', 0.32641375064849854),\n",
       " ('carob', 0.3258015811443329),\n",
       " ('horsy', 0.3257073163986206),\n",
       " ('subdued', 0.3256458640098572),\n",
       " ('remover', 0.32549765706062317),\n",
       " ('animal', 0.3254569470882416),\n",
       " ('evaporate', 0.32280153036117554),\n",
       " ('batter', 0.32188498973846436),\n",
       " ('mocke', 0.32170823216438293),\n",
       " ('mediterranean', 0.32150891423225403),\n",
       " ('pinched', 0.32046160101890564),\n",
       " ('dill', 0.32019221782684326),\n",
       " ('woodland', 0.31951162219047546),\n",
       " ('perpetual', 0.31900298595428467),\n",
       " ('candied', 0.3189573585987091),\n",
       " ('settles', 0.3185652792453766),\n",
       " ('loads', 0.31777089834213257),\n",
       " ('incense', 0.317704439163208)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.most_similar('aromas', topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lamb', 0.8895524740219116),\n",
       " ('chops', 0.8595080971717834),\n",
       " ('potatoes', 0.8537752628326416),\n",
       " ('meats', 0.8528634309768677),\n",
       " ('sausage', 0.8490621447563171),\n",
       " ('roast', 0.8372448682785034),\n",
       " ('stew', 0.8363399505615234),\n",
       " ('risotto', 0.8271031975746155),\n",
       " ('veal', 0.8163446187973022),\n",
       " ('chicken', 0.8158363103866577),\n",
       " ('tenderloin', 0.8108752369880676),\n",
       " ('beef', 0.8078727722167969),\n",
       " ('dish', 0.8061364889144897),\n",
       " ('duck', 0.805750846862793),\n",
       " ('steaks', 0.8040581941604614),\n",
       " ('sausages', 0.7944930195808411),\n",
       " ('broiled', 0.7938192486763),\n",
       " ('barbecued', 0.7880339026451111),\n",
       " ('lasagna', 0.7877833843231201),\n",
       " ('braised', 0.779943585395813),\n",
       " ('ham', 0.7761930823326111),\n",
       " ('sauce', 0.7709249258041382),\n",
       " ('ribs', 0.7707759737968445),\n",
       " ('oven', 0.7700439691543579),\n",
       " ('rib', 0.7694214582443237),\n",
       " ('pastas', 0.769004762172699),\n",
       " ('venison', 0.7595199346542358),\n",
       " ('cheeses', 0.757583737373352),\n",
       " ('roasts', 0.757253110408783),\n",
       " ('tuna', 0.7561944127082825),\n",
       " ('brisket', 0.7557617425918579),\n",
       " ('shrimp', 0.754752516746521),\n",
       " ('tartare', 0.7546616792678833),\n",
       " ('gratin', 0.7546499967575073),\n",
       " ('filet', 0.7522172927856445),\n",
       " ('teriyaki', 0.7513728141784668),\n",
       " ('halibut', 0.7513222694396973),\n",
       " ('barbecue', 0.7509827017784119),\n",
       " ('meatloaf', 0.7484983801841736),\n",
       " ('stews', 0.7471663355827332),\n",
       " ('hamburger', 0.7469497919082642),\n",
       " ('scallops', 0.7457247376441956),\n",
       " ('sauces', 0.7411941885948181),\n",
       " ('fowl', 0.7393152713775635),\n",
       " ('grill', 0.738851010799408),\n",
       " ('stuffed', 0.7334486842155457),\n",
       " ('lobster', 0.7330219745635986),\n",
       " ('marinara', 0.7326080203056335),\n",
       " ('soup', 0.7324010729789734),\n",
       " ('pizza', 0.7320111989974976)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.most_similar('pork', topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find wines based on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wine_finder(query):\n",
    "    query_rank = tfidf_vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_rank, tfidf_matrix).flatten()\n",
    "    related_docs_indices = sims.argsort()[:-8:-1]\n",
    "    return related_docs_indices, sims[related_docs_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wine_results_printer(query):\n",
    "    print('The top wines that much the query (', query, '):')\n",
    "    doc_indices, similarities = wine_finder(query)\n",
    "    for index, doc_index in enumerate(doc_indices):\n",
    "        print(index, ')', wine['description'][doc_index])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the flavours and notes you are looking for your wine: \n",
      "['cherry', 'berry', 'plum', 'apple', 'blackberry', 'vanilla', 'pepper', 'citrus', 'lemon', 'raspberry', 'peach', 'pear', 'chocolate', 'currant', 'licorice', 'lime', 'coffee', 'melon', 'grapefruit', 'honey', 'apricot', 'pineapple', 'strawberry', 'cinnamon', 'almond', 'mocha', 'mint', 'orange', 'jam', 'grape', 'blueberry', 'tea', 'sage', 'pie', 'caramel', 'cranberry', 'raisin', 'olive', 'tomato', 'coconut', 'butter', 'bacon', 'fig', 'mango', 'banana', 'thyme', 'prune', 'mushroom', 'pomegranate', 'butterscotch', 'ginger', 'lychee', 'mousse', 'bread', 'nut', 'truffle', 'yeast', 'jasmine', 'nectarine', 'hazelnut', 'fennel', 'liqueur', 'tart', 'herbs', 'quince', 'dill', 'watermelon', 'heart', 'lamb', 'pork', 'chicken', 'guava', 'seafood', 'maple', 'custard', 'energy', 'soy', 'beer', 'cooking', 'coating']\n"
     ]
    }
   ],
   "source": [
    "print('Select the flavours and notes you are looking for your wine: ')\n",
    "print(foods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top wines that much the query ( plum vanilla jam ):\n",
      "0 ) Blackberry jam aromas lead to a fruity wine, soft and juicy. Fresh and rounded, it has balanced acidity and an open, generous character. Drink now.\n",
      "\n",
      "1 ) Soft and dull, with blackberry and cherry jam and sweet vanilla flavors. The tannins and acids both are low. Not going anywhere.\n",
      "\n",
      "2 ) Made entirely from Sangiovese, this opens with aromas of black plum, vanilla and toast. The concentrated palate doles out black cherry jam, cedar and tobacco alongside assertive tannins. Drink through 2019.\n",
      "\n",
      "3 ) Made entirely from Sangiovese, this opens with aromas of black plum, vanilla and toast. The concentrated palate doles out black cherry jam, cedar and tobacco alongside assertive tannins. Drink through 2019.\n",
      "\n",
      "4 ) A little heavy and syrupy, but for twelve bucks, you get a creamy wine with pineapple jam and vanilla flavors.\n",
      "\n",
      "5 ) Plum-jam-flavored wine, this is very sweet, rich and very direct. The freshness is here, but this is more about the dense, superripe fruits.\n",
      "\n",
      "6 ) Made predominantly from Sangiovese, this has delicate black-skinned fruit and brown spice aromas. The palate is simple, with vanilla-laced black plum fruit and laid-back tannins. Drink soon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'plum vanilla jam'\n",
    "wine_results_printer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print wines based on alternative queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_dictionary = dict()\n",
    "for index, word in enumerate(query.split()):\n",
    "    similarity_dictionary[word] = [word[0] for word in cbow_model.wv.most_similar(word, topn=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls = []\n",
    "for index, word in enumerate(query.split()):\n",
    "    for similar_word in similarity_dictionary[word]:\n",
    "        temporary_list = query.split()\n",
    "        temporary_list[index] = similar_word\n",
    "        ls.append(temporary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_results_printer(query)\n",
    "for new_query in ls:\n",
    "    query = \" \".join(new_query)\n",
    "    wine_results_printer(query)\n",
    "    print('=======================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
